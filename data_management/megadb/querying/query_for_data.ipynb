{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = 'all'  # default is ‘last_expr'\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('/Users/siyuyang/Source/repos/GitHub_MSFT/CameraTraps')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "from collections import Counter\n",
    "import io\n",
    "from random import sample\n",
    "\n",
    "from tqdm import tqdm\n",
    "from azure.cosmos.cosmos_client import CosmosClient\n",
    "from azure.storage.blob import BlockBlobService\n",
    "from PIL import Image\n",
    "\n",
    "from visualization import visualization_utils, visualize_megadb\n",
    "from data_management.annotations import annotation_constants"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Query for data\n",
    "\n",
    "This notebook demonstrates the workflow to compile desired sequences of images by querying metadata and downloading the images stored in blob storage.\n",
    "\n",
    "See the programs that Chris prepared here (internal): https://celads.visualstudio.com/CELA%20Data%20Science%20And%20Analytics/_git/DSnA.CameraTrap?path=%2FPython%2Fclientpr.py\n",
    "\n",
    "`COSMOS_ENDPOINT` and `COSMOS_KEY` need to be environment variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize Cosmos DB client\n",
    "url = os.environ['COSMOS_ENDPOINT']\n",
    "key = os.environ['COSMOS_KEY']\n",
    "client = CosmosClient(url, credential=key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "database = client.get_database_client('camera-trap')\n",
    "container_datasets = database.get_container_client('datasets')\n",
    "container_sequences = database.get_container_client('sequences')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Store the `datasets` table\n",
    "which records the location and access levels of each dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of results: 18\n",
      "CPU times: user 15 ms, sys: 3.1 ms, total: 18.1 ms\n",
      "Wall time: 403 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "query = '''SELECT * FROM datasets d'''\n",
    "\n",
    "result_iterable = container_datasets.query_items(query=query, enable_cross_partition_query=True)\n",
    "\n",
    "datasets = {i['dataset_name']:{k: v for k, v in i.items() if not k.startswith('_')} for i in iter(result_iterable)}\n",
    "\n",
    "print('Length of results:', len(datasets))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Select image entries\n",
    "\n",
    "Example: top 1000 images from a given dataset with bounding boxes, selecting the file name and the dataset so we can plot the labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 87 µs, sys: 1 µs, total: 88 µs\n",
      "Wall time: 92.3 µs\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "result_iterable = container_sequences.query_items(\n",
    "    query='''\n",
    "SELECT TOP @top_n seq\n",
    "FROM sequences seq JOIN im IN seq.images \n",
    "WHERE ARRAY_LENGTH(im.bbox) > 0\n",
    "''',\n",
    "    parameters=[\n",
    "        dict(name='@top_n', value=1000)\n",
    "    ],\n",
    "    partition_key='wps_190624'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = [{k: v for k, v in r['seq'].items() if not k.startswith('_')} for r in iter(result_iterable)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'images': [{'file': 'ec2906a8-6e78-4351-9c7f-330b9a60f6ec.jpg',\n",
       "   'image_id': 'ec2906a8-6e78-4351-9c7f-330b9a60f6ec',\n",
       "   'bbox': [{'category': 'animal', 'bbox': [0.00125, 0.5612, 0.2025, 0.2113]},\n",
       "    {'category': 'animal', 'bbox': [0.4989, 0.5437, 0.08856, 0.1343]},\n",
       "    {'category': 'animal', 'bbox': [0.5021, 0.5223, 0.08235, 0.07782]},\n",
       "    {'category': 'animal', 'bbox': [0.4405, 0.5373, 0.07755, 0.07768]},\n",
       "    {'category': 'animal', 'bbox': [0.3837, 0.505, 0.0587, 0.07389]},\n",
       "    {'category': 'animal', 'bbox': [0.3887, 0.5416, 0.05981, 0.1566]},\n",
       "    {'category': 'animal', 'bbox': [0.4605, 0.549, 0.04557, 0.1481]},\n",
       "    {'category': 'animal', 'bbox': [0.6711, 0.456, 0.03345, 0.1085]}],\n",
       "   'class': ['__label_unavailable']}],\n",
       " 'seq_id': 'dummy_3b960f28c6e54010903d3d02d1dfe695',\n",
       " 'dataset': 'wps_190624',\n",
       " 'class': ['human'],\n",
       " 'id': 'd852d02a-cffd-4a66-bd80-4bfe2c9971ff'}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results[-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Download sample images and visualize labels\n",
    "\n",
    "For large batches, download using `multiprocessing.ThreadPool`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_size = 2\n",
    "sample_res = sample(results, sample_size)\n",
    "\n",
    "for seq in sample_res:\n",
    "    for im in seq['images']:\n",
    "        if 'bbox' not in im or len(im['bbox']) == 0:\n",
    "            continue\n",
    "    \n",
    "        dataset = seq['dataset']\n",
    "        storage_account = datasets[dataset]['storage_account']\n",
    "        storage_container = datasets[dataset]['container']\n",
    "        storage_sas_key = datasets[dataset]['container_sas_key']\n",
    "        path_prefix = datasets[dataset]['path_prefix']\n",
    "\n",
    "        blob_service = visualize_megadb.get_blob_service(datasets, dataset)\n",
    "        stream = io.BytesIO()\n",
    "        _ = blob_service.get_blob_to_stream(storage_container, os.path.join(path_prefix, im['file']), stream)\n",
    "        image = Image.open(stream)\n",
    "\n",
    "        visualization_utils.render_megadb_bounding_boxes(im['bbox'], image)\n",
    "        print('from dataset {}'.format(dataset))\n",
    "        image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:cameratraps] *",
   "language": "python",
   "name": "conda-env-cameratraps-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
