{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = 'all' # default is ‘last_expr’\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'10.0.0'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import azure.batch\n",
    "azure.batch.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "from azure.batch import BatchServiceClient\n",
    "from azure.batch.batch_auth import SharedKeyCredentials\n",
    "from azure.batch.models import PoolAddParameter, BatchErrorException, VirtualMachineConfiguration, ImageReference, JobAddParameter,\\\n",
    "TaskAddParameter, PoolInformation\n",
    "from azure.common.credentials import ServicePrincipalCredentials"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Azure Batch\n",
    "\n",
    "Documentation\n",
    "- https://github.com/azurebigcompute/Recipes/tree/master/Azure%20Batch/CustomImages\n",
    "- https://github.com/Azure-Samples/batch-python-quickstart/blob/master/src/python_quickstart_client.py#L343\n",
    "- https://github.com/Azure-Samples/azure-batch-samples/tree/master/Python/Batch\n",
    "\n",
    "TODO\n",
    "\n",
    "- Turn `enable_auto_scale` on and set the appropriate `auto_scale_formula`. This way we can cap the maximum available nodes. https://docs.microsoft.com/en-us/azure/batch/batch-automatic-scaling\n",
    "\n",
    "## Create a pool for each instance of the API\n",
    "\n",
    "Listing all versions of a SKU of image:\n",
    "```\n",
    "az vm image list --all --publisher microsoft-dsvm\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ['BATCH_ACCOUNT_NAME'] = ''\n",
    "os.environ['BATCH_ACCOUNT_URL'] = 'https://'\n",
    "\n",
    "os.environ['APP_CLIENT_ID'] = ''\n",
    "os.environ['APP_CLIENT_SECRET'] = ''\n",
    "os.environ['APP_TENANT_ID'] = ''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "POOL_ID = 'internal_1'\n",
    "assert len(POOL_ID) <= 64, 'pool_id has more than 64 characters'\n",
    "\n",
    "POOL_NODE_COUNT = 1\n",
    "\n",
    "POOL_VM_SIZE = 'Standard_NC6s_v3'  # https://docs.microsoft.com/en-us/azure/virtual-machines/ncv3-series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_batch_exception(batch_exception):\n",
    "    \"\"\"\n",
    "    Prints the contents of the specified Batch exception.\n",
    "    \"\"\"\n",
    "    print('-------------------------------------------')\n",
    "    print('Exception encountered:')\n",
    "    if batch_exception.error and \\\n",
    "            batch_exception.error.message and \\\n",
    "            batch_exception.error.message.value:\n",
    "        print(batch_exception.error.message.value)\n",
    "        if batch_exception.error.values:\n",
    "            print()\n",
    "            for mesg in batch_exception.error.values:\n",
    "                print(f'{mesg.key}:\\t{mesg.value}')\n",
    "    print('-------------------------------------------')\n",
    "    \n",
    "def create_pool(batch_service_client, pool_id):\n",
    "    \"\"\"\n",
    "    Found the DSVM image among the supported images using `az batch pool supported-images list`\n",
    "    {\n",
    "        \"batchSupportEndOfLife\": null,\n",
    "        \"capabilities\": [\n",
    "          \"NvidiaTeslaDriverInstalled\"\n",
    "        ],\n",
    "        \"imageReference\": {\n",
    "          \"offer\": \"ubuntu-1804\",\n",
    "          \"publisher\": \"microsoft-dsvm\",\n",
    "          \"sku\": \"1804\",\n",
    "          \"version\": \"latest\",\n",
    "          \"virtualMachineImageId\": null\n",
    "        },\n",
    "        \"nodeAgentSkuId\": \"batch.node.ubuntu 18.04\",\n",
    "        \"osType\": \"linux\",\n",
    "        \"verificationType\": \"unverified\"\n",
    "      }\n",
    "    \"\"\"\n",
    "    new_pool = PoolAddParameter(\n",
    "        id=POOL_ID,\n",
    "        display_name=POOL_ID,\n",
    "        \n",
    "        vm_size=POOL_VM_SIZE,\n",
    "        \n",
    "#         virtual_machine_configuration=VirtualMachineConfiguration(\n",
    "#             image_reference= ImageReference(\n",
    "#                 publisher=\"microsoft-dsvm\",\n",
    "#                 offer=\"ubuntu-1804\",\n",
    "#                 sku=\"1804\",\n",
    "#                 version=\"latest\"\n",
    "#             ),\n",
    "#             node_agent_sku_id=\"batch.node.ubuntu 18.04\"),\n",
    "        virtual_machine_configuration=VirtualMachineConfiguration(\n",
    "            image_reference= ImageReference(\n",
    "                publisher=\"microsoft-azure-batch\",\n",
    "                offer=\"ubuntu-server-container\",\n",
    "                sku=\"16-04-lts\",\n",
    "                version=\"latest\"\n",
    "            ),\n",
    "            node_agent_sku_id=\"batch.node.ubuntu 16.04\"),\n",
    "        \n",
    "        target_dedicated_nodes=POOL_NODE_COUNT, # we only used dedicated nodes\n",
    "        \n",
    "    )\n",
    "    batch_service_client.pool.add(new_pool)\n",
    "\n",
    "def create_job():\n",
    "    pass\n",
    "\n",
    "def create_task():\n",
    "    \"\"\"\n",
    "    All Tasks should be idempotent as they may need to be retried due to a recovery operation.\n",
    "    \"\"\"\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "account_url = os.environ['BATCH_ACCOUNT_URL']\n",
    "\n",
    "app_client_id = os.environ['APP_CLIENT_ID']\n",
    "app_client_secret = os.environ['APP_CLIENT_SECRET']\n",
    "app_tenant_id = os.environ['APP_TENANT_ID']\n",
    "\n",
    "credentials = ServicePrincipalCredentials(\n",
    "    client_id=app_client_id,\n",
    "    secret=app_client_secret,\n",
    "    tenant=app_tenant_id,\n",
    "    resource=\"https://batch.core.windows.net/\"\n",
    ")\n",
    "\n",
    "# if using the Batch quota system, use https://docs.microsoft.com/en-us/python/api/azure-batch/azure.batch.batch_auth.sharedkeycredentials?view=azure-python\n",
    "# to authenticate instead of the service principal is also okay.\n",
    "\n",
    "batch_client = BatchServiceClient(credentials=credentials, batch_url=account_url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    create_pool(batch_client, POOL_ID)\n",
    "except BatchErrorException as e:\n",
    "    print_batch_exception(e)\n",
    "    raise"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Submitting a job\n",
    "\n",
    "Job is what we have been referring to as Requests. Each shard corresponds to a Task.\n",
    "\n",
    "The Azure Batch service sets these environment variables on the compute nodes:\n",
    "\n",
    "- AZ_BATCH_JOB_ID\n",
    "\n",
    "- AZ_BATCH_TASK_ID\n",
    "- AZ_BATCH_TASK_DIR\n",
    "- AZ_BATCH_TASK_WORKING_DIR - currently running task has read/write access to this directory\n",
    "\n",
    "```\n",
    "python -c 'import tensorflow as tf; print(tf.__version__); print(f'is gpu available {tf.test.is_gpu_available()}');'\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "job_id = 'test2'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# job id is the request id in the old API context\n",
    "\n",
    "job = JobAddParameter(\n",
    "    id=job_id,\n",
    "    pool_info=PoolInformation(pool_id=POOL_ID),\n",
    ")\n",
    "\n",
    "batch_client.job.add(job)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Submit tasks to the job (the shards)\n",
    "\n",
    "After creating a user and logging into the node, \n",
    "\n",
    "`py37_tensorflow` conda environment is available, TF version is 2.3.1 (boto is 2.2.0), command to check GPU is `tf.config.list_physical_devices('GPU')`\n",
    "\n",
    "```\n",
    ">>> tf.config.list_physical_devices('GPU')\n",
    "2021-01-12 05:54:31.745248: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1716] Found device 0 with properties: \n",
    "pciBusID: 8bbe:00:00.0 name: Tesla V100-PCIE-16GB computeCapability: 7.0\n",
    "coreClock: 1.38GHz coreCount: 80 deviceMemorySize: 15.78GiB deviceMemoryBandwidth: 836.37GiB/s\n",
    "2021-01-12 05:54:31.745301: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1\n",
    "2021-01-12 05:54:31.745452: W tensorflow/stream_executor/platform/default/dso_loader.cc:59] Could not load dynamic library 'libcublas.so.10'; dlerror: libcublas.so.10: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /opt/intel/compilers_and_libraries_2018.1.163/linux/tbb/lib/intel64_lin/gcc4.7:/opt/intel/compilers_and_libraries_2018.1.163/linux/compiler/lib/intel64_lin:/opt/intel/compilers_and_libraries_2018.1.163/linux/mkl/lib/intel64_lin::/usr/local/cuda/lib64:/usr/local/cuda/extras/CUPTI/lib64/\n",
    "2021-01-12 05:54:31.745479: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcufft.so.10\n",
    "2021-01-12 05:54:31.745498: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcurand.so.10\n",
    "2021-01-12 05:54:31.745515: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcusolver.so.10\n",
    "2021-01-12 05:54:31.745531: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcusparse.so.10\n",
    "2021-01-12 05:54:31.745549: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudnn.so.7\n",
    "2021-01-12 05:54:31.745560: W tensorflow/core/common_runtime/gpu/gpu_device.cc:1753] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.\n",
    "```\n",
    "\n",
    "GPU information:\n",
    "```\n",
    "| NVIDIA-SMI 455.32.00    Driver Version: 455.32.00    CUDA Version: 11.1\n",
    "```\n",
    "\n",
    "Okay, looks like (https://www.tensorflow.org/install/source#gpu) CUDA 11 is only supported by TF 2.4+. So let's look into containers..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "command = \"\"\"/bin/bash -c \"conda activate py37_tensorflow && python -c 'import tensorflow as tf; print(tf.__version__); print(tf.test.is_gpu_available())'\" \"\"\"\n",
    "\n",
    "task = TaskAddParameter(\n",
    "        id='task_{}'.format(0),\n",
    "        command_line=command\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_client.task.add(job_id, task)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run container applications\n",
    "\n",
    "https://docs.microsoft.com/en-us/azure/batch/batch-docker-container-workloads"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Monitoring a job\n",
    "\n",
    "Optimization: remember which tasks have already Completed so that we do not repeatedly query for their status."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:cameratraps-batch-api]",
   "language": "python",
   "name": "conda-env-cameratraps-batch-api-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
