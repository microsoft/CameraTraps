{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Megadetector_Colab_test.ipynb",
      "provenance": [],
      "private_outputs": true,
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s-Nso4g7VXxy",
        "colab_type": "text"
      },
      "source": [
      "<a href=\"https://colab.research.google.com/github/microsoft/CameraTraps/blob/master/detection/megadetector_colab.ipynb\">\n",
      "  <img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open in Colab\"/>\n",
      "</a>\n",
      "\n",
      "This notebook replaces a previous example by [@louis030195](https://github.com/louis030195). Improvements: updated environment file, MegaDetector model version and support for mounting Google Drive folders so you can process your own images here."
     ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vUXNQZtwEYiQ",
        "colab_type": "text"
      },
      "source": [
        "# Running MegaDetector on camera trap images using Google Colab\n",
        "Put together by Alistair Stewart, Alice Springs, May 2020.\n",
        "@alsnothome\n",
        "\n",
        "For reference please read the [MegaDetector guide on GitHub](https://github.com/microsoft/CameraTraps/blob/master/megadetector.md) and check there for updates. Here we have roughly followed the steps for running under Linux. \n",
        "\n",
        "This notebook is designed to load camera trap image files already uploaded onto Google Drive. The steps walk through the copying of all of the required model and helper files to the Colab runtime and install all the required packages. You can then connect to your Google Drive folder and process all of the images in a folder using the MegaDetector saved model. The output is saved in a JSON file - a text based database file whose format is described in this [section](https://github.com/microsoft/CameraTraps/tree/master/api/batch_processing#batch-processing-api-output-format) in the batch API user guide. The detections (as bounding boxes) can then be rendered on your images. The Google Colab instance will only stay open for a maximum 10-12 hrs and after that it will close and any unsaved data will be lost. I recommend saving the JSON output and annotated images into your Google Drive folder for persistent storage. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9aUlxnm7cnWy",
        "colab_type": "text"
      },
      "source": [
        "## Set up the Colab instance to run on GPU processing\n",
        "\n",
        "\n",
        "Navigate to Editâ†’Notebook Settings and select \"GPU\" from the Hardware Accelerator drop-down "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LUyqKSAWRGNw",
        "colab_type": "text"
      },
      "source": [
        "## Copy the model, install dependencies, set PYTHONPATH\n",
        "\n",
        "Note: from here on you'll start seeing a mix of code. Most of it is Linux system commands, rather than Python. The system commands are prefixed by a shebang `!`, which tells this notebook to execute them on the command line."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hXn_-PZqTWB4",
        "colab_type": "text"
      },
      "source": [
        "### Download the MegaDetector model file:\n",
        "\n",
        "Currently, v4.1 is avaialble by direct download. The link can be found in the GitHub MegaDetector readme: MegaDetector v4.1, 2020.04.27 frozen model (.pb)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s5uwmpmaTZMX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!wget -O /content/megadetector_v4_1_0.pb https://lilablobssc.blob.core.windows.net/models/camera_traps/megadetector/md_v4.1.0/md_v4.1.0.pb"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nmJ6lQX8S4im",
        "colab_type": "text"
      },
      "source": [
        "### Clone the two required Microsoft git repos:\n",
        "This will copy the latest version of the Microsoft AI for Earth \"utilities\" and \"Camera Traps\" repositories from GitHub. These make data handling and running the model easy. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7qhltAaRSe1W",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!git clone https://github.com/microsoft/CameraTraps\n",
        "!git clone https://github.com/microsoft/ai4eutils"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XQTdfBPZiXiV",
        "colab_type": "text"
      },
      "source": [
        "We'll also copy the Python scripts that run the model and produce visualization of results to the working directory."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t4Ns5PjeiTro",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!cp /content/CameraTraps/detection/run_tf_detector_batch.py /content/run_tf_detector_batch.py \n",
        "!cp /content/CameraTraps/visualization/visualize_detector_output.py /content/visualize_detector_output.py"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2pzfM5Y-iby1",
        "colab_type": "text"
      },
      "source": [
        "### Set `PYTHONPATH` to include `CameraTraps` and `ai4eutils`\n",
        "\n",
        "Add cloned git folders to `PYTHONPATH`:\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d8vanlgAOlEj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os\n",
        "os.environ['PYTHONPATH'] += \":/content/ai4eutils\"\n",
        "os.environ['PYTHONPATH'] += \":/content/CameraTraps\"\n",
        "\n",
        "print(\"PYTHONPATH: \")\n",
        "! echo $PYTHONPATH"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ddPlAKHFTn3m",
        "colab_type": "text"
      },
      "source": [
        "### Install TensorFlow\n",
        "\n",
        "TensorFlow is already installed in Colab, but it is more straightforward to run MegaDetector with the existing scripts using an older version than the Colab standard of 2.x . Here we install the older TensorFlow version using `pip`, with GPU processing by specifying `-gpu` and version number `1.13.1`. \n",
        "\n",
        "We also install the other required Python packages that are not already in Colab - `humanfriendly` and `jsonpickle`."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EMEkgpy6T0pr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "pip install tensorflow-gpu==1.13.1 humanfriendly jsonpickle"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JyjEgkCsOsak",
        "colab_type": "text"
      },
      "source": [
        "## Mount Google Drive in Colab:\n",
        "Once you run the cell below, it will show a URL and a text box.\n",
        "\n",
        "Visit that URL to choose the Google account where the images you want to process live. After you authenticate, an authorization code will be shown. Copy the authorization code to the text box here. \n",
        "\n",
        "Your Google Drive folders will then be mounted under `/content/drive` and can be viewed and navigated in the Files pane.\n",
        "\n",
        "The method is described under this Colab code snippet: https://colab.research.google.com/notebooks/io.ipynb#scrollTo=u22w3BFiOveA. Never give out your account username and password. Read this Colab code snippet to understand how this connection is made and authenticated. There are other ways to connect your Google Drive or upload your data if you do not find this method suitable."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XYsrTTR7eF0r",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Lkugt7r3uUEr",
        "colab_type": "text"
      },
      "source": [
        "## MegaDetector batch processing\n",
        "\n",
        "This step executes the Python script `run_tf_detector_batch.py` that we copied from the CameraTraps repo. It has three mandatory arguments and one optional:\n",
        "1.   path to the MegaDetector saved model file.\n",
        "2.   a folder on your Google Drive containing the images - replace `[Image_Folder]` with your folder name.\n",
        "3.   the output JSON file location and name - replace `[Output_Folder]` with your folder name and `[output_file_name.json]` with your file name.\n",
        "4.   option `--recursive` goes through all subfolders to find and process all images within.\n",
        "\n",
        "You will need to change the image folder path and output file path, depending on your situation.\n",
        "\n",
        "In our experience the Colab system will take ~30 seconds to intialize and load the saved MegaDetector model. It will then iterate through all of the images in the folder specified. Processing initially takes a few seconds per image and usually settles to ~1.3 sec per image. That is ~45 images per miute or ~2700 images per hour. Limit the number of images in your folder so that all of the processing can be completed before the Colab session ends.\n",
        "\n",
        "If you see the error \"AssertionError: output_file specified needs to end with .json\" then you haven't update the output folder and file name in the line of code below properly."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pSIH-k0nfi73",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "images_dir = '/content/drive/My Drive/[Image Folder]'\n",
        "\n",
        "# choose a location for the output JSON file\n",
        "output_file_path = '/content/drive/My Drive/[Output Folder]/[output_file_name.json]'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Bsvuux-yhpLw",
        "colab_type": "text"
      },
      "source": [
        "Here we pass the Python variable value `output_file_path` you specified above to the bash commands below using `$` (double quoting as there are spaces in this path), to run the script. This is so that we can refer to the output file path later for visualization. \n",
        "\n",
        "Also remember to modify `[Image Folder]` below!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3AOKfviGuTNg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!python run_tf_detector_batch.py megadetector_v4_1_0.pb \"$images_dir\" \"$output_file_path\" --recursive"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-tHu5WUGDpcd",
        "colab_type": "text"
      },
      "source": [
        "## Visualize batch processing script outputs\n",
        "\n",
        "Here we use the `visualize_detector_output.py` in the `visualization` folder of the Camera Traps repo to see the output of the MegaDetector visualized on our images. It will save images annotated with the results (original images will *not* be modified) to the `[Visualization Folder]` you specify here.\n",
        "\n",
        "The scripts take in a number of optional parameters to control output image size and how many are sampled (if you've processed a lot of images but only want to visualize the results on a few) - take a look at the `main()` function in the script to see what other parameters are available."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iv6ph0l1obhr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "visualization_dir = '/content/[Visualization Folder]'  # pick a location for annotated images"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "en3TbCftkWDE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!python visualize_detector_output.py \"$output_file_path\" \"$visualization_dir\" --confidence 0.8 --images_dir \"$images_dir\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O0AYUcBlm9BN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from PIL import Image"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AglNEK0goyjA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "for viz_file_name in os.listdir(visualization_dir):\n",
        "  print(viz_file_name)\n",
        "  im = Image.open(os.path.join(visualization_dir, viz_file_name))\n",
        "  display(im)  # display() is an iPython method that comes with the notebook"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}
