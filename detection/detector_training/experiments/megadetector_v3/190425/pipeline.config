model {
  faster_rcnn {
    # we continue to use 90 classes so all pretrained detector arm weights can be used
    num_classes: 90
    image_resizer {
      keep_aspect_ratio_resizer {
        min_dimension: 600
        max_dimension: 1024
      }
    }
    feature_extractor {
      type: "faster_rcnn_inception_resnet_v2"
      first_stage_features_stride: 8
    }
    first_stage_anchor_generator {
      grid_anchor_generator {
        height_stride: 8
        width_stride: 8
        scales: 0.25
        scales: 0.5
        scales: 1.0
        scales: 2.0
        aspect_ratios: 0.5
        aspect_ratios: 1.0
        aspect_ratios: 2.0
      }
    }
    first_stage_atrous_rate: 2
    first_stage_box_predictor_conv_hyperparams {
      op: CONV
      regularizer {
        l2_regularizer {
          weight: 0.0
        }
      }
      initializer {
        truncated_normal_initializer {
          stddev: 0.00999999977648
        }
      }
    }
    first_stage_nms_score_threshold: 0.0
    first_stage_nms_iou_threshold: 0.699999988079
    first_stage_max_proposals: 300
    first_stage_localization_loss_weight: 2.0
    first_stage_objectness_loss_weight: 1.0
    initial_crop_size: 17
    maxpool_kernel_size: 1
    maxpool_stride: 1
    second_stage_box_predictor {
      mask_rcnn_box_predictor {
        fc_hyperparams {
          op: FC
          regularizer {
            l2_regularizer {
              weight: 0.0
            }
          }
          initializer {
            variance_scaling_initializer {
              factor: 1.0
              uniform: true
              mode: FAN_AVG
            }
          }
        }
        use_dropout: false
        dropout_keep_probability: 1.0
      }
    }
    second_stage_post_processing {
      batch_non_max_suppression {
        score_threshold: 0.0
        iou_threshold: 0.600000023842
        max_detections_per_class: 100
        max_total_detections: 100
      }
      score_converter: SOFTMAX
    }
    second_stage_localization_loss_weight: 2.0
    second_stage_classification_loss_weight: 1.0
  }
}
train_config {
  batch_size: 1
  data_augmentation_options {
    random_crop_image {
      min_object_covered: 0.800000011921
      min_area: 0.800000011921
    }
  }
  keep_checkpoint_every_n_hours: 1
  optimizer {
    momentum_optimizer {
      learning_rate {
        manual_step_learning_rate {
          initial_learning_rate: 0.000003
          schedule {
            step: 600000
            learning_rate: 0.000003
          }
        }
      }
      momentum_optimizer_value: 0.899999976158
    }
    use_moving_average: false
  }
  gradient_clipping_by_norm: 10.0
  # To resume from previous checkpoint, it needs to be specified in model_dir/checkpoint and copied to model_dir
  # loading weight from this specified path only works at the start
  # Initial run, uncomment the following lines
  #fine_tune_checkpoint_type: "detection"
  #load_all_detection_checkpoint_vars: true
  # fine_tune_checkpoint: "/megadetectorv3/pretrained/faster_rcnn_inception_resnet_v2_atrous_coco_2018_01_28/model.ckpt"
}
train_input_reader {
  label_map_path: "/megadetectorv3/PyCharm/CameraTraps/detection/experiments/megadetector_v3/label_map.pbtxt"
  tf_record_input_reader {
    input_path: "/disk/megadetectorv3_tfrecords/???????~train-?????-of-?????"
  }
  max_number_of_boxes: 200
}
eval_config {
  metrics_set: "coco_detection_metrics"
  use_moving_averages: false
  num_visualizations: 300
}
eval_input_reader {
  label_map_path: "/megadetectorv3/PyCharm/CameraTraps/detection/experiments/megadetector_v3/label_map.pbtxt"
  shuffle: true
  num_readers: 1
  tf_record_input_reader {
    input_path: "/disk/megadetectorv3_tfrecords/???????~val__-?????-of-?????"
  }
}
