model {
  faster_rcnn {
    # we continue to use 90 classes so all pretrained detector arm weights can be used
    num_classes: 90
    image_resizer {
      keep_aspect_ratio_resizer {
        min_dimension: 600
        max_dimension: 1024
      }
    }
    feature_extractor {
      type: "faster_rcnn_inception_resnet_v2"
      first_stage_features_stride: 8
    }
    first_stage_anchor_generator {
      grid_anchor_generator {
        height_stride: 8
        width_stride: 8
        scales: 0.25
        scales: 0.5
        scales: 1.0
        scales: 2.0
        aspect_ratios: 0.5
        aspect_ratios: 1.0
        aspect_ratios: 2.0
      }
    }
    first_stage_atrous_rate: 2
    first_stage_box_predictor_conv_hyperparams {
      op: CONV
      regularizer {
        l2_regularizer {
          weight: 0.0
        }
      }
      initializer {
        truncated_normal_initializer {
          stddev: 0.00999999977648
        }
      }
    }
    first_stage_nms_score_threshold: 0.0
    first_stage_nms_iou_threshold: 0.699999988079
    first_stage_max_proposals: 300
    first_stage_localization_loss_weight: 2.0
    first_stage_objectness_loss_weight: 1.0
    initial_crop_size: 17
    maxpool_kernel_size: 1
    maxpool_stride: 1
    second_stage_box_predictor {
      mask_rcnn_box_predictor {
        fc_hyperparams {
          op: FC
          regularizer {
            l2_regularizer {
              weight: 0.0
            }
          }
          initializer {
            variance_scaling_initializer {
              factor: 1.0
              uniform: true
              mode: FAN_AVG
            }
          }
        }
        use_dropout: false
        dropout_keep_probability: 1.0
      }
    }
    second_stage_post_processing {
      batch_non_max_suppression {
        score_threshold: 0.0
        iou_threshold: 0.600000023842
        max_detections_per_class: 100
        max_total_detections: 100
      }
      score_converter: SOFTMAX
    }
    second_stage_localization_loss_weight: 2.0
    second_stage_classification_loss_weight: 1.0
  }
}
train_config {
  batch_size: 1
  data_augmentation_options {
    random_crop_image {
      min_object_covered: 0.800000011921
      min_area: 0.800000011921
    }
    # Randomly horizontally flips the image and detections 50% of the time.
    random_horizontal_flip {
    }
    # Randomly rotates the image and detections by 90 degrees counter-clockwise
    # 50% of the time.
    random_rotation90 {
    }
    random_rgb_to_gray {
      probability: 0.05
    }
    random_adjust_brightness {
      max_delta: 0.2
    }
    random_adjust_contrast {
      min_delta: 0.8
      max_delta: 1.25
    }
    random_adjust_hue {
      max_delta: 0.02
    }
    random_adjust_saturation {
      min_delta: 0.8
      max_delta: 1.25
    }
    # Performs a random color distortion. color_orderings should either be 0 or 1.
    random_distort_color {
      color_ordering: 1
    }
    random_black_patches {
      max_black_patches: 3
      probability: 0.1,
      size_to_image_ratio: 0.1
    }
  }
  keep_checkpoint_every_n_hours: 1
  optimizer {
    momentum_optimizer {
      learning_rate {
        manual_step_learning_rate {
          initial_learning_rate: 0.0
          schedule {
            step: 2000
            learning_rate: 0.0003
          }
          schedule {
                step: 760000
                learning_rate: 0.00003
          }
          warmup: true
        }
      }
      momentum_optimizer_value: 0.899999976158
    }
    use_moving_average: false
  }
  gradient_clipping_by_norm: 10.0
  fine_tune_checkpoint_type: "detection"
  load_all_detection_checkpoint_vars: true
  fine_tune_checkpoint: "$AZUREML_DATAREFERENCE_artifacts/pretrained/faster_rcnn_inception_resnet_v2_atrous_coco_2018_01_28/model.ckpt"
}
train_input_reader {
  label_map_path: "$AZUREML_DATAREFERENCE_artifacts/label_map.pbtxt"
  tf_record_input_reader {
    input_path: "$AZUREML_DATAREFERENCE_tfrecords/mdv4boxes_train-?????-of-?????"
  }
  max_number_of_boxes: 200
}
eval_config {
  metrics_set: "coco_detection_metrics"
  use_moving_averages: false
  num_visualizations: 300
}
eval_input_reader {
  label_map_path: "$AZUREML_DATAREFERENCE_artifacts/label_map.pbtxt"
  shuffle: true
  num_readers: 1
  tf_record_input_reader {
    input_path: "$AZUREML_DATAREFERENCE_tfrecords/mdv4boxes_val__-?????-of-?????"
  }
}