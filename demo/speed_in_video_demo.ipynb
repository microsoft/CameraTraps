{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4210d6e4",
   "metadata": {},
   "source": [
    "\n",
    "# ðŸ¾ Wildlife Speed Tracking\n",
    "\n",
    "Welcome! This notebook helps you **detect, classify, and estimate 2D speeds** of animals in videos using **PyTorchWildlife**.  \n",
    "\n",
    "> **What youâ€™ll get**: Annotated videos saved to an output folder, plus a `speed.csv` summarizing speeds per tracked object."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ffe19d7",
   "metadata": {},
   "source": [
    "\n",
    "## âœ… Requirements\n",
    "\n",
    "- Python 3.9+ recommended\n",
    "- GPU optional (CUDA speeds things up, but CPU works too)\n",
    "- Videos placed in a folder (default: `./demo_data/speed_tracking_videos`)\n",
    "\n",
    "### ðŸ“¦ Install dependencies\n",
    "\n",
    "> If you already have the packages, you can **skip** this cell. If needed, uncomment to install (recommended to run one-by-one if you hit errors)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30510b97",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# %pip install --upgrade pip\n",
    "# %pip install supervision\n",
    "# %pip install ipywidgets tqdm pandas matplotlib\n",
    "# %pip install PytorchWildlife\n",
    "# %pip install torch torchvision torchaudio\n",
    "# %pip install display"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28a116ed",
   "metadata": {},
   "source": [
    "\n",
    "## ðŸ“¥ Imports\n",
    "This cell imports everything we need and validates the environment.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7b1b6cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "from pathlib import Path\n",
    "from typing import Tuple, List\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from tqdm import tqdm\n",
    "import torch\n",
    "import supervision as sv\n",
    "\n",
    "from PytorchWildlife.models import detection as pw_detection\n",
    "from PytorchWildlife.models import classification as pw_classification\n",
    "from PytorchWildlife import utils as pw_utils\n",
    "\n",
    "print(\"Torch version:\", torch.__version__)\n",
    "print(\"CUDA available:\", torch.cuda.is_available())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6b066ee",
   "metadata": {},
   "source": [
    "\n",
    "## ðŸŽ›ï¸ Configure Inputs\n",
    "\n",
    "- **Height (optional):** Use the cell below to set `animal_height_m` in meters to convert speeds from **px/s â†’ m/s** (conversion: `m/s = (px/s * animal_height_m) / image_width_px`). Leave it `None` to keep speeds in **px/s**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ed0a80c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "animal_height_m = None\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f14285a8",
   "metadata": {},
   "source": [
    "- **Video content:** Use the cell below to specify what your videos contain. This choice controls how tracks are selected:\n",
    "\n",
    "    - *One individual* â†’ keep only the single longest track (best when a single animal is present).\n",
    "    - *Group of animals* â†’ keep all tracks (best when multiple animals may appear)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3a2d846",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "assume_single_individual = False\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87768843",
   "metadata": {},
   "source": [
    "\n",
    "- **Folders**: where videos live and where outputs should go."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7dfe637d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "SOURCE_FOLDER_PATH = os.path.join(\".\", \"demo_data\", \"speed_tracking_videos\")\n",
    "OUTPUT_FOLDER = os.path.join(\".\", \"speed_tracking_output\")\n",
    "\n",
    "Path(OUTPUT_FOLDER).mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "print(f\"SOURCE_FOLDER_PATH = {SOURCE_FOLDER_PATH}\")\n",
    "print(f\"OUTPUT_FOLDER      = {OUTPUT_FOLDER}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99b07fa2",
   "metadata": {},
   "source": [
    "\n",
    "## ðŸ–¥ï¸ Device\n",
    "Selects GPU (CUDA) if available, otherwise CPU.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cad197c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "if DEVICE == \"cuda\":\n",
    "    try:\n",
    "        dev_name = torch.cuda.get_device_name(0)\n",
    "    except Exception:\n",
    "        dev_name = \"CUDA device\"\n",
    "    print(f\"Using GPU: {dev_name}\")\n",
    "else:\n",
    "    print(\"Using CPU (this may be slower).\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cc63596",
   "metadata": {},
   "source": [
    "\n",
    "## ðŸ§  Load Models\n",
    "- **Detector**: MegaDetector V6 (YOLOv9-c backbone)\n",
    "- **Classifier**: AI4G Amazon Rainforest (v2)\n",
    "\n",
    "> First run may download weights. If downloads fail, check internet/firewall settings.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e910260",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# You can switch versions here if needed.\n",
    "DETECTION_VERSION = \"MDV6-yolov9-c\"\n",
    "CLASSIFICATION_VERSION = \"v2\"\n",
    "\n",
    "try:\n",
    "    detection_model = pw_detection.MegaDetectorV6(device=DEVICE, pretrained=True, version=DETECTION_VERSION)\n",
    "    classification_model = pw_classification.AI4GAmazonRainforest(device=DEVICE, version=CLASSIFICATION_VERSION)\n",
    "    print(\"âœ… Models loaded\")\n",
    "except Exception as e:\n",
    "    raise RuntimeError(\n",
    "        \"Failed to load models. Verify your PyTorchWildlife install and network access for weights.\"\n",
    "    ) from e\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bde0c14",
   "metadata": {},
   "source": [
    "\n",
    "## ðŸ–ï¸ Annotators\n",
    "Configure bounding boxes and labels for the output videos.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4964cba",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "box_annotator = sv.BoxAnnotator(thickness=4)\n",
    "lab_annotator = sv.LabelAnnotator(text_color=sv.Color.BLACK, text_thickness=4, text_scale=2)\n",
    "print(\"Annotators ready.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "366f5cf9",
   "metadata": {},
   "source": [
    "\n",
    "## ðŸ” Detection & Classification Callback\n",
    "\n",
    "This function:\n",
    "1. Detects animals in the frame  \n",
    "2. Classifies each detection (cropped region)  \n",
    "3. Draws boxes & labels for visualization\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95ce9a07",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from typing import Dict\n",
    "\n",
    "def callback(frame: np.ndarray, index: int) -> Tuple[np.ndarray, sv.Detections, List[Tuple[str, float]]]:\n",
    "    \"\"\"\n",
    "    Args:\n",
    "        frame: Current video frame (H,W,3)\n",
    "        index: Frame index or identifier (passed to detector for metadata)\n",
    "    Returns:\n",
    "        annotated_frame: Frame with boxes+labels\n",
    "        detections: Supervision Detections object\n",
    "        clf_labels: List of (prediction, confidence) per detection in the same order\n",
    "    \"\"\"\n",
    "    results_det: Dict = detection_model.single_image_detection(frame, img_path=index)\n",
    "\n",
    "    clf_labels: List[Tuple[str, float]] = []\n",
    "    for xyxy in results_det[\"detections\"].xyxy:\n",
    "        cropped_image = sv.crop_image(image=frame, xyxy=xyxy)\n",
    "        results_clf = classification_model.single_image_classification(cropped_image)\n",
    "        clf_labels.append((results_clf[\"prediction\"], results_clf[\"confidence\"]))\n",
    "\n",
    "    annotated_frame = lab_annotator.annotate(\n",
    "        scene=box_annotator.annotate(scene=frame, detections=results_det[\"detections\"]),\n",
    "        detections=results_det[\"detections\"],\n",
    "        labels=results_det[\"labels\"]\n",
    "    )\n",
    "\n",
    "    return annotated_frame, results_det[\"detections\"], clf_labels\n",
    "\n",
    "print(\"Callback ready.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58919afd",
   "metadata": {},
   "source": [
    "\n",
    "## ðŸ“Š Prepare Speed Table\n",
    "Weâ€™ll create a DataFrame that stores **t1/x1/y1 â†’ t2/x2/y2** and a computed speed column:\n",
    "- If a **species** is chosen, speeds convert to **m/s**\n",
    "- Otherwise, speeds remain in **px/s**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55ce2cb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def init_speed_df(species_name: str):\n",
    "    if animal_height_m:\n",
    "        cols = [\"Video\", \"Image Width (px)\", \"Image Height (px)\", \"t1 (s)\", \"x1 (px)\", \"y1 (px)\", \"label1\", \"t2 (s)\", \"x2 (px)\", \"y2 (px)\", \"label2\", \"speed (m/s)\"]\n",
    "        print(f\"Using height ~ {animal_height_m} m for conversion.\")\n",
    "        return pd.DataFrame(columns=cols), animal_height_m, True\n",
    "    else:\n",
    "        cols = [\"Video\", \"Image Width (px)\", \"Image Height (px)\", \"t1 (s)\", \"x1 (px)\", \"y1 (px)\", \"label1\", \"t2 (s)\", \"x2 (px)\", \"y2 (px)\", \"label2\", \"speed (px/s)\"]\n",
    "        print(\"No animal height specified. Speed will be in pixels/second.\")\n",
    "        return pd.DataFrame(columns=cols), None, False\n",
    "\n",
    "df, animal_height_m, using_meters = init_speed_df(animal_height_m)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b140cc0",
   "metadata": {},
   "source": [
    "\n",
    "## â–¶ï¸ Run Tracking on Your Videos\n",
    "\n",
    "- Place videos in `SOURCE_FOLDER_PATH` (e.g., `.mp4, .avi, .mov`).\n",
    "- Annotated videos will be written into `OUTPUT_FOLDER`.\n",
    "- A running **speed table** is built and saved as `speed.csv` at the end.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "705de025",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, uuid, cv2\n",
    "import logging\n",
    "logging.getLogger(\"ultralytics\").setLevel(logging.CRITICAL)\n",
    "\n",
    "if not os.path.exists(SOURCE_FOLDER_PATH):\n",
    "    raise FileNotFoundError(f\"Source video folder not found at {SOURCE_FOLDER_PATH}. Please create it and add videos.\")\n",
    "\n",
    "tracks = 0\n",
    "video_files = [f for f in os.listdir(SOURCE_FOLDER_PATH) if f.lower().endswith((\".mp4\", \".avi\", \".mov\"))]\n",
    "\n",
    "if not video_files:\n",
    "    print(\"No video files found. Add videos to the source folder and re-run this cell.\")\n",
    "else:\n",
    "    iterator = video_files\n",
    "    if tqdm is not None:\n",
    "        iterator = tqdm(video_files, desc=\"Processing videos\")\n",
    "\n",
    "    for video_name in iterator:\n",
    "        SOURCE_VIDEO_PATH = os.path.join(SOURCE_FOLDER_PATH, video_name)\n",
    "        TARGET_VIDEO_PATH = os.path.join(OUTPUT_FOLDER, f\"{os.path.splitext(video_name)[0]}_tracked.mp4\")\n",
    "        temp_basename = f\"{os.path.splitext(video_name)[0]}_{uuid.uuid4().hex}.tmp.mp4\"\n",
    "        TEMP_VIDEO_PATH = os.path.join(OUTPUT_FOLDER, temp_basename)\n",
    "        print(f\"\\nProcessing: {video_name}\")\n",
    "\n",
    "        try:\n",
    "            image_width_px, image_height_px, track_summaries = pw_utils.speed_in_video(\n",
    "                source_path=SOURCE_VIDEO_PATH,\n",
    "                target_path=TEMP_VIDEO_PATH,\n",
    "                callback=callback,\n",
    "                target_fps=10,\n",
    "                codec=\"mp4v\",\n",
    "                longest=assume_single_individual,\n",
    "                min_points=6,\n",
    "                min_duration_s=0.5,\n",
    "                min_displacement_px=20,\n",
    "                suppress_subtracks=True,\n",
    "                subtrack_radius_px=50,\n",
    "            )\n",
    "\n",
    "            os.replace(TEMP_VIDEO_PATH, TARGET_VIDEO_PATH)\n",
    "\n",
    "            # Each 'track' has two points (t1,x1,y1) and (t2,x2,y2) and a speed in px/s\n",
    "            for i, key in enumerate(track_summaries):\n",
    "                t1, x1, y1 = track_summaries[key]['points'][0]\n",
    "                t2, x2, y2 = track_summaries[key]['points'][1]\n",
    "                speed_px_s = track_summaries[key]['speed']\n",
    "                label1, label2 = track_summaries[key]['labels']\n",
    "\n",
    "                if using_meters and animal_height_m:\n",
    "                    # Convert px/s to m/s using width-scale (height_m / image_width_px)\n",
    "                    speed_val = (speed_px_s * animal_height_m) / image_width_px\n",
    "                else:\n",
    "                    speed_val = speed_px_s\n",
    "\n",
    "                df.loc[tracks] = [video_name, image_width_px, image_height_px, t1, x1, y1, label1, t2, x2, y2, label2, speed_val]\n",
    "                tracks += 1\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"âš ï¸ Error processing {video_name}: {e}\")\n",
    "            if os.path.exists(TEMP_VIDEO_PATH):\n",
    "                    os.remove(TEMP_VIDEO_PATH)\n",
    "            continue\n",
    "\n",
    "print(\"\\nDone.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "496f2ed6",
   "metadata": {},
   "source": [
    "\n",
    "## ðŸ’¾ Save Results\n",
    "This writes a `speed.csv` into your output folder.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1729bc5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "csv_path = os.path.join(OUTPUT_FOLDER, \"speed.csv\")\n",
    "if len(df) > 0:\n",
    "    df.to_csv(csv_path, index=False, float_format=\"%.3f\")\n",
    "    print(f\"Saved: {csv_path}\")\n",
    "    display(df)\n",
    "else:\n",
    "    print(\"Speed table is emptyâ€”nothing to save yet.\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch-wildlife",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
